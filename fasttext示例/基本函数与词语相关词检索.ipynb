{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. fasttext基本函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 加载fasttext词语向量并打印fasttext模型的帮助文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext使用C++写的，官网提供了Python的接口https://github.com/facebookresearch/fastText/tree/master/python 。还有一个使用 fastText的Python库叫做pyfasttext,但是它已经不再维护了https://github.com/vrasneur/pyfasttext 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _FastText in module fastText.FastText object:\n",
      "\n",
      "class _FastText(builtins.object)\n",
      " |  _FastText(model=None)\n",
      " |  \n",
      " |  This class defines the API to inspect models and should not be used to\n",
      " |  create objects. It will be returned by functions such as load_model or\n",
      " |  train.\n",
      " |  \n",
      " |  In general this API assumes to be given only unicode for Python2 and the\n",
      " |  Python3 equvalent called str for any string-like arguments. All unicode\n",
      " |  strings are then encoded as UTF-8 and fed to the fastText C++ API.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_dimension(self)\n",
      " |      Get the dimension (size) of a lookup vector (hidden layer).\n",
      " |  \n",
      " |  get_input_matrix(self)\n",
      " |      Get a copy of the full input matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_input_vector(self, ind)\n",
      " |      Given an index, get the corresponding vector of the Input Matrix.\n",
      " |  \n",
      " |  get_labels(self, include_freq=False, on_unicode_error='strict')\n",
      " |      Get the entire list of labels of the dictionary optionally\n",
      " |      including the frequency of the individual labels. Unsupervised\n",
      " |      models use words as labels, which is why get_labels\n",
      " |      will call and return get_words for this type of\n",
      " |      model.\n",
      " |  \n",
      " |  get_line(self, text, on_unicode_error='strict')\n",
      " |      Split a line of text into words and labels. Labels must start with\n",
      " |      the prefix used to create the model (__label__ by default).\n",
      " |  \n",
      " |  get_output_matrix(self)\n",
      " |      Get a copy of the full output matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_sentence_vector(self, text)\n",
      " |      Given a string, get a single vector represenation. This function\n",
      " |      assumes to be given a single line of text. We split words on\n",
      " |      whitespace (space, newline, tab, vertical tab) and the control\n",
      " |      characters carriage return, formfeed and the null character.\n",
      " |  \n",
      " |  get_subword_id(self, subword)\n",
      " |      Given a subword, return the index (within input matrix) it hashes to.\n",
      " |  \n",
      " |  get_subwords(self, word, on_unicode_error='strict')\n",
      " |      Given a word, get the subwords and their indicies.\n",
      " |  \n",
      " |  get_word_id(self, word)\n",
      " |      Given a word, get the word id within the dictionary.\n",
      " |      Returns -1 if word is not in the dictionary.\n",
      " |  \n",
      " |  get_word_vector(self, word)\n",
      " |      Get the vector representation of word.\n",
      " |  \n",
      " |  get_words(self, include_freq=False, on_unicode_error='strict')\n",
      " |      Get the entire list of words of the dictionary optionally\n",
      " |      including the frequency of the individual words. This\n",
      " |      does not include any subwords. For that please consult\n",
      " |      the function get_subwords.\n",
      " |  \n",
      " |  is_quantized(self)\n",
      " |  \n",
      " |  predict(self, text, k=1, threshold=0.0, on_unicode_error='strict')\n",
      " |      Given a string, get a list of labels and a list of\n",
      " |      corresponding probabilities. k controls the number\n",
      " |      of returned labels. A choice of 5, will return the 5\n",
      " |      most probable labels. By default this returns only\n",
      " |      the most likely label and probability. threshold filters\n",
      " |      the returned labels by a threshold on probability. A\n",
      " |      choice of 0.5 will return labels with at least 0.5\n",
      " |      probability. k and threshold will be applied together to\n",
      " |      determine the returned labels.\n",
      " |      \n",
      " |      This function assumes to be given\n",
      " |      a single line of text. We split words on whitespace (space,\n",
      " |      newline, tab, vertical tab) and the control characters carriage\n",
      " |      return, formfeed and the null character.\n",
      " |      \n",
      " |      If the model is not supervised, this function will throw a ValueError.\n",
      " |      \n",
      " |      If given a list of strings, it will return a list of results as usually\n",
      " |      received for a single line of text.\n",
      " |  \n",
      " |  quantize(self, input=None, qout=False, cutoff=0, retrain=False, epoch=None, lr=None, thread=None, verbose=None, dsub=2, qnorm=False)\n",
      " |      Quantize the model reducing the size of the model and\n",
      " |      it's memory footprint.\n",
      " |  \n",
      " |  save_model(self, path)\n",
      " |      Save the model to the given path\n",
      " |  \n",
      " |  test(self, path, k=1)\n",
      " |      Evaluate supervised model using file given by path\n",
      " |  \n",
      " |  test_label(self, path, k=1, threshold=0.0)\n",
      " |      Return the precision and recall score for each label.\n",
      " |      \n",
      " |      The returned value is a dictionary, where the key is the label.\n",
      " |      For example:\n",
      " |      f.test_label(...)\n",
      " |      {'__label__italian-cuisine' : {'precision' : 0.7, 'recall' : 0.74}}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastText import load_model\n",
    "fasttext_model = load_model(r'cc.zh.300.bin')\n",
    "help(fasttext_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 fasttext模型基本方法演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表长度= 2000000\n",
      "词汇表前100个词\n",
      " ['，', '的', '。', '</s>', '、', '是', '一', '在', '：', '了', '（', '）', \"'\", '和', '不', '有', '我', ',', ')', '(', '“', '”', '也', '人', '个', ':', '中', '.', '就', '他', '》', '《', '-', '你', '都', '上', '大', '！', '这', '为', '多', '与', '章', '「', '到', '」', '要', '？', '被', '而', '能', '等', '可以', '年', '；', '|', '以', '及', '之', '公司', '对', '中国', '很', '会', '小', '但', '我们', '最', '更', '/', '1', '三', '新', '自己', '可', '2', '或', '次', '好', '将', '第', '种', '她', '…', '3', '地', '對', '用', '工作', '下', '后', '由', '两', '使用', '还', '又', '您', '?', '其', '已']\n",
      "词语向量维度= 300\n",
      "\"是\"字在词汇表中以及词语向量矩阵中的索引id 5\n",
      "词语\"是\"的向量长度= 1.6197449\n",
      "比较两种获取词语\"是\"向量的方法是否一致? True\n"
     ]
    }
   ],
   "source": [
    "# 获取词汇表\n",
    "words = fasttext_model.get_words()\n",
    "# 打印词汇表长度\n",
    "print(\"词汇表长度=\", len(words))\n",
    "# 打印词汇表前100个词\n",
    "print(\"词汇表前100个词\\n\", words[:100])\n",
    "# 打印词语向量的维度\n",
    "print(\"词语向量维度=\",fasttext_model.get_dimension())\n",
    "# 获取“是”字在词汇表中以及词语向量矩阵中的索引id\n",
    "print('\"是\"字在词汇表中以及词语向量矩阵中的索引id', fasttext_model.get_word_id(\"是\"))\n",
    "# 通过id获取词语\"是\"向量\n",
    "vec_by_id = fasttext_model.get_input_vector(5)\n",
    "# 打印向量长度\n",
    "import numpy as np\n",
    "print('词语\"是\"的向量长度=', np.linalg.norm(vec_by_id))\n",
    "# fasttext向量库中的词语向量不是单位向量，如果使用余弦相似度查找最相似的词，则需要事先对词语向量进行归一化处理\n",
    "# 通过词语获取词语“是”的词语向量\n",
    "vec_by_word = fasttext_model.get_word_vector(\"是\")\n",
    "print('比较两种获取词语\"是\"向量的方法是否一致?', np.linalg.norm(vec_by_id) == np.linalg.norm(vec_by_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 计算与\"直升机\"最相似的词语列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 首先对fasttext词语向量矩阵的每个词向量（行向量）归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vec与model_vec一致吗? True\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 获取整个fasttext向量矩阵\n",
    "fasttext_vec = fasttext_model.get_input_matrix()[:len(fasttext_model.get_words())]\n",
    "# 验证读取处的向量矩阵是否正确\n",
    "input_vec = fasttext_vec[fasttext_model.get_word_id(\"的\")]\n",
    "model_vec = fasttext_model.get_word_vector(\"的\")\n",
    "print(\"input_vec与model_vec一致吗?\", np.linalg.norm(input_vec) == np.linalg.norm(model_vec))\n",
    "# 对fasttext向量矩阵的每个词向量（行向量）归一化\n",
    "fasttext_vec = (fasttext_vec.T/np.linalg.norm(fasttext_vec,axis=1)).T\n",
    "# 获取“的”的词语向量\n",
    "word_vec = fasttext_vec[fasttext_model.get_word_id(\"的\")]\n",
    "# 输出“的”的向量长度\n",
    "print(np.linalg.norm(word_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 检索与\"直升机\"相关的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('直升机', 1.0), ('直升飞机', 0.77804565), ('飞机', 0.71779704), ('直升機', 0.6616683), ('米-171', 0.6531244), ('米-8', 0.6311184), ('停机坪', 0.6279004), ('救援机', 0.6260574), ('NH-90', 0.62192786), ('Z-9', 0.6202519)]\n",
      "[('直升飞机', 0.77804565), ('飞机', 0.71779704), ('直升機', 0.6616683), ('米-171', 0.6531244), ('米-8', 0.6311184), ('停机坪', 0.6279004), ('救援机', 0.6260574), ('NH-90', 0.62192786), ('Z-9', 0.6202519), ('旋翼机', 0.61378306)]\n"
     ]
    }
   ],
   "source": [
    "# 获取直升机的向量\n",
    "word_vec = fasttext_vec[fasttext_model.get_word_id(\"直升机\")]\n",
    "# 计算直升机向量与库中每个词的相似度\n",
    "sim_vec = np.dot(word_vec, fasttext_vec.T)\n",
    "# 按相似度排序词语\n",
    "sorted_sim_vec = sorted(zip(fasttext_model.get_words(), sim_vec), key=lambda x:x[1], reverse=True)\n",
    "# 获取与直升机最相似的top10词语列表，\n",
    "print(sorted_sim_vec[:10])\n",
    "# 把词语直升机自己去除掉\n",
    "print(sorted_sim_vec[1:10+1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
